{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97ea5aab-8c4b-449f-9d0d-a5f1fb1e52ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, to_timestamp, avg, count, window, date_format\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType\n",
    "\n",
    "import dlt\n",
    "\n",
    "# Define the schema for the Kafka data\n",
    "schema = StructType() \\\n",
    "    .add(\"DeviceID\", StringType()) \\\n",
    "    .add(\"CustomerID\", StringType()) \\\n",
    "    .add(\"Timestamp\", StringType()) \\\n",
    "    .add(\"Region\", StringType()) \\\n",
    "    .add(\"SignalStrength\", DoubleType()) \\\n",
    "    .add(\"CallDropRate\", DoubleType()) \\\n",
    "    .add(\"DataTransferSpeed\", DoubleType()) \\\n",
    "    .add(\"ComplaintType\", StringType()) \\\n",
    "    .add(\"CustomerSatisfaction\", DoubleType())\n",
    "\n",
    "# BRONZE LAYER\n",
    "@dlt.table(\n",
    "  comment=\"Raw data ingested from Kafka topic: 'projecttest'.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"bronze\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def bronze_kafka_data():\n",
    "  kafka_df = (spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"65.0.75.84:9092\")\n",
    "    .option(\"subscribe\", \"projecttest\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .option(\"failOnDataLoss\", \"false\")  # Ignore missing data errors\n",
    "    .load())\n",
    "\n",
    "  \n",
    "  # Cast value to string and parse the JSON structure\n",
    "  return kafka_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "      .select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "# SILVER LAYER\n",
    "@dlt.table(\n",
    "  comment=\"Cleaned and filtered data from Bronze, partitioned by 'Region'.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"silver\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_signal_strength\", \"SignalStrength BETWEEN 0 AND 100\")\n",
    "@dlt.expect_or_drop(\"valid_call_drop_rate\", \"CallDropRate BETWEEN 0 AND 10\")\n",
    "@dlt.expect_or_drop(\"valid_data_transfer_speed\", \"DataTransferSpeed BETWEEN 5 AND 100\")\n",
    "def silver_cleaned_data():\n",
    "  bronze_data = dlt.read_stream(\"bronze_kafka_data\")\n",
    "  \n",
    "  # Convert the timestamp field and clean the data\n",
    "  cleaned_data = bronze_data.withColumn(\n",
    "      \"Timestamp\", to_timestamp(\"Timestamp\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "  \n",
    "  return cleaned_data\n",
    "\n",
    "# GOLD LAYER: Signal Strength Trend\n",
    "@dlt.table(\n",
    "  comment=\"Signal Strength trend over time for each customer.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"gold\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def signal_strength_trend():\n",
    "  silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "  \n",
    "  return silver_data.groupBy(window(\"Timestamp\", \"1 day\"), \"CustomerID\")\\\n",
    "      .agg(avg(\"SignalStrength\").alias(\"AvgSignalStrength\"))\\\n",
    "      .orderBy(\"window.start\")\n",
    "\n",
    "# GOLD LAYER: Call Drop Rate Analysis\n",
    "@dlt.table(\n",
    "  comment=\"Average Call Drop Rate for each customer.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"gold\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def call_drop_rate_analysis():\n",
    "  silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "  \n",
    "  return silver_data.groupBy(\"CustomerID\")\\\n",
    "      .agg(avg(\"CallDropRate\").alias(\"AvgCallDropRate\"))\n",
    "\n",
    "# GOLD LAYER: Data Transfer Speed Comparison\n",
    "@dlt.table(\n",
    "  comment=\"Average Data Transfer Speed per month for each customer.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"gold\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def data_transfer_speed_comparison():\n",
    "  silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "  \n",
    "  return silver_data.withColumn(\"Month\", date_format(\"Timestamp\", \"yyyy-MM\"))\\\n",
    "      .groupBy(\"Month\", \"CustomerID\")\\\n",
    "      .agg(avg(\"DataTransferSpeed\").alias(\"AvgDataTransferSpeed\"))\n",
    "\n",
    "# GOLD LAYER: Geographical Heatmap\n",
    "@dlt.table(\n",
    "  comment=\"Average Signal Strength by region.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"gold\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def geographical_heatmap():\n",
    "  silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "  \n",
    "  return silver_data.groupBy(\"Region\")\\\n",
    "      .agg(avg(\"SignalStrength\").alias(\"AvgSignalStrength\"))\n",
    "\n",
    "# GOLD LAYER: Customer Complaints Analysis\n",
    "@dlt.table(\n",
    "  comment=\"Complaint type distribution.\",\n",
    "  table_properties={\n",
    "    \"quality\": \"gold\",\n",
    "    \"pipelines.autoOptimize.managed\": \"true\"\n",
    "  }\n",
    ")\n",
    "def complaints_analysis():\n",
    "  silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "  \n",
    "  return silver_data.groupBy(\"ComplaintType\")\\\n",
    "      .agg(count(\"*\").alias(\"ComplaintCount\"))\n",
    "\n",
    "# Uncomment to implement Customer Satisfaction Analysis\n",
    "# GOLD LAYER: Satisfaction vs Call Drop Rate\n",
    "# @dlt.table(\n",
    "#   comment=\"Correlation between Customer Satisfaction and Call Drop Rates.\",\n",
    "#   table_properties={\n",
    "#     \"quality\": \"gold\",\n",
    "#     \"pipelines.autoOptimize.managed\": \"true\"\n",
    "#   }\n",
    "# )\n",
    "# def satisfaction_vs_call_drop():\n",
    "#   silver_data = dlt.read_stream(\"silver_cleaned_data\")\n",
    "#   return silver_data.groupBy(\"CustomerID\")\\\n",
    "#       .agg(avg(\"CallDropRate\").alias(\"AvgCallDropRate\"), avg(\"CustomerSatisfaction\").alias(\"AvgCustomerSatisfaction\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
